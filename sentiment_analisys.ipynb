{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import nltk.classify.util\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_csv('amazon-cell-phones-reviews/20190928-reviews.csv')\n",
    "df_reviews.loc[df_reviews['rating'] <= 3, 'liked'] = False\n",
    "df_reviews.loc[df_reviews['rating'] > 3, 'liked'] = True\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82815, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_index:57970\n"
     ]
    }
   ],
   "source": [
    "threshold_factor = 0.7\n",
    "model_index = int(threshold_factor * len(df_reviews))\n",
    "print(f'model_index:{model_index}')\n",
    "df_model_data = df_reviews.iloc[:model_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_factor = 0.8\n",
    "\n",
    "positive_reviews = df_model_data[df_model_data['liked'] == True]\n",
    "negative_reviews = df_model_data[df_model_data['liked'] == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_str = 'this is a sentence.and this other 12.90'\n",
    "re.sub(\"[^\\w]\", \" \",  m_str).split()\n",
    "def get_list_words(reviews_str):\n",
    "    token = str(reviews_str)\n",
    "    return re.sub(\"[^\\w]\", \" \",  token).split()\n",
    "\n",
    "def extract_features(word_list):\n",
    "    return dict([(word, True) for word in word_list if word.lower() not in stop_words])\n",
    "#if word not in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_series = [get_list_words(review) for review in positive_reviews['body'].values]\n",
    "negative_series = [get_list_words(review) for review in negative_reviews['body'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_features = [(extract_features(a_review), 'Positive') for a_review in positive_series]\n",
    "negative_features = [(extract_features(a_review), 'Negative') for a_review in negative_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36984\n",
      "20986\n"
     ]
    }
   ],
   "source": [
    "print(len(positive_features))\n",
    "print(len(negative_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test (80/20)\n",
    "threshold_factor = 0.8\n",
    "threshold_positive = int(threshold_factor * len(positive_features))\n",
    "threshold_negative = int(threshold_factor * len(negative_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of training datapoints: 46375\n",
      "Number of test datapoints: 11595\n"
     ]
    }
   ],
   "source": [
    "features_train = positive_features[:threshold_positive] + negative_features[:threshold_negative]\n",
    "features_test = positive_features[threshold_positive:] + negative_features[threshold_negative:]  \n",
    "print(\"\\nNumber of training datapoints:\", len(features_train))\n",
    "print(\"Number of test datapoints:\", len(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the classifier: 0.8146614920224234\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(features_train)\n",
    "print(\"\\nAccuracy of the classifier:\", nltk.classify.util.accuracy(classifier, features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                Horrible = True           Negati : Positi =     88.7 : 1.0\n",
      "                   Waste = True           Negati : Positi =     74.6 : 1.0\n",
      "            Disappointed = True           Negati : Positi =     66.4 : 1.0\n",
      "                   Worst = True           Negati : Positi =     65.2 : 1.0\n",
      "               Excelente = True           Positi : Negati =     57.7 : 1.0\n",
      "               Returning = True           Negati : Positi =     55.8 : 1.0\n",
      "                Terrible = True           Negati : Positi =     51.1 : 1.0\n",
      "                  Return = True           Negati : Positi =     45.2 : 1.0\n",
      "                  LOCKED = True           Negati : Positi =     42.9 : 1.0\n",
      "                 Perfect = True           Positi : Negati =     35.9 : 1.0\n",
      "                   Avoid = True           Negati : Positi =     35.8 : 1.0\n",
      "                  BEWARE = True           Negati : Positi =     32.5 : 1.0\n",
      "             paperweight = True           Negati : Positi =     26.9 : 1.0\n",
      "               excelente = True           Positi : Negati =     25.5 : 1.0\n",
      "                flickers = True           Negati : Positi =     25.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Naive Bayes Algo accuracy percent: 81.46614920224235\n",
      "Most Informative Features\n",
      "                Horrible = True           Negati : Positi =     88.7 : 1.0\n",
      "                   Waste = True           Negati : Positi =     74.6 : 1.0\n",
      "            Disappointed = True           Negati : Positi =     66.4 : 1.0\n",
      "                   Worst = True           Negati : Positi =     65.2 : 1.0\n",
      "               Excelente = True           Positi : Negati =     57.7 : 1.0\n",
      "               Returning = True           Negati : Positi =     55.8 : 1.0\n",
      "                Terrible = True           Negati : Positi =     51.1 : 1.0\n",
      "                  Return = True           Negati : Positi =     45.2 : 1.0\n",
      "                  LOCKED = True           Negati : Positi =     42.9 : 1.0\n",
      "                 Perfect = True           Positi : Negati =     35.9 : 1.0\n",
      "                   Avoid = True           Negati : Positi =     35.8 : 1.0\n",
      "                  BEWARE = True           Negati : Positi =     32.5 : 1.0\n",
      "             paperweight = True           Negati : Positi =     26.9 : 1.0\n",
      "               excelente = True           Positi : Negati =     25.5 : 1.0\n",
      "                flickers = True           Negati : Positi =     25.3 : 1.0\n",
      "MNB_classifier accuracy percent: 87.46873652436395\n",
      "BernoulliNB_classifier accuracy percent: 80.7416990081932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e-rbnunez\\AppData\\Local\\Continuum\\anaconda3\\envs\\cerounoDS\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier accuracy percent: 87.79646399310047\n",
      "SGDClassifier_classifier accuracy percent: 87.90858128503666\n",
      "LinearSVC_classifier accuracy percent: 86.3130659767141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e-rbnunez\\AppData\\Local\\Continuum\\anaconda3\\envs\\cerounoDS\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(classifier, features_test))*100)\n",
    "classifier.show_most_informative_features(15)\n",
    "\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(features_train)\n",
    "print(\"MNB_classifier accuracy percent:\", (nltk.classify.accuracy(MNB_classifier, features_test))*100)\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(features_train)\n",
    "print(\"BernoulliNB_classifier accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier, features_test))*100)\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(features_train)\n",
    "print(\"LogisticRegression_classifier accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier, features_test))*100)\n",
    "\n",
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGDClassifier_classifier.train(features_train)\n",
    "print(\"SGDClassifier_classifier accuracy percent:\", (nltk.classify.accuracy(SGDClassifier_classifier, features_test))*100)\n",
    "\n",
    "#SVC_classifier = SklearnClassifier(SVC())\n",
    "#SVC_classifier.train(features_train)\n",
    "#print(\"SVC_classifier accuracy percent:\", (nltk.classify.accuracy(SVC_classifier, features_test))*100)\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(features_train)\n",
    "print(\"LinearSVC_classifier accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier, features_test))*100)\n",
    "\n",
    "#NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "#NuSVC_classifier.train(features_train)\n",
    "#print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, features_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d3d454b9687e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNuSVC_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSklearnClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNuSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mNuSVC_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NuSVC_classifier accuracy percent:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNuSVC_classifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cerounoDS\\lib\\site-packages\\nltk\\classify\\scikitlearn.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, labeled_featuresets)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cerounoDS\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cerounoDS\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 random_seed)\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\cerounoDS\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NuSVC_classifier = SklearnClassifier(NuSVC(gamma='auto', cache_size=7000))\n",
    "NuSVC_classifier.train(features_train)\n",
    "print(\"NuSVC_classifier accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier, features_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnoceroClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "    \n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for a_classifier in self._classifiers:\n",
    "            a_vote = a_classifier.classify(features)\n",
    "            votes.append(a_vote)\n",
    "        return mode(votes)\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for a_classifier in self._classifiers:\n",
    "            a_vote = a_classifier.classify(features)\n",
    "            votes.append(a_vote)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        return choice_votes / len(votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unocero_classifier accuracy percent: 88.1845623113411\n"
     ]
    }
   ],
   "source": [
    "unocero_classifier = UnoceroClassifier(classifier,\n",
    "                                  #NuSVC_classifier,\n",
    "                                  LinearSVC_classifier,\n",
    "                                  SGDClassifier_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  #BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"unocero_classifier accuracy percent:\", (nltk.classify.accuracy(unocero_classifier, features_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_test[11][0])\n",
    "print(\"Classification:\", unocero_classifier.classify(features_test[0][0]), \"Confidence %:\",unocero_classifier.confidence(features_test[0][0])*100)\n",
    "print(\"Classification:\", unocero_classifier.classify(features_test[1][0]), \"Confidence %:\",unocero_classifier.confidence(features_test[1][0])*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
